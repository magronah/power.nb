---
title: "Power and Sample Size Estimation for Microbiome Analysis"
date: "`r Sys.Date()`"
author: "Michael Agronah and Benjamin Bolker"
output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
    df_print: paged
  pdf_document: default
vignette: >
  %\VignetteIndexEntry{Simulation for microbiome power analysis}
  %\VignettePackage{power.nb}
  %\VignetteEngine{knitr::rmarkdown}
bibliography: references.bib
---


# Acknowledgments

We would like to express our sincere gratitude to Dr. Jacob T. Nearing for his generosity in granting access to the 38 microbiome datasets used in the paper “Microbiome differential abundance methods produce different results across 38 datasets” [@Nearing2022]. These datasets were invaluable in developing, testing, and validating this R package for power and sample size calculation in microbiome studies.

#  Package Description and Functionalies 

`power.nb` is a package developed for estimating statistical power and sample sizes in differential abundance microbiome studies. The package presents novel methods for estimating statistical power for individual taxa (feature, otu, or species) and for sample size calculation accounting for effect sizes and mean abundance of taxa.


`power.nb` also presents two novel microbiome data simulations frameworks: `MixGassSim` and `RRSim`. The method implemented in `MixGassSim` models the distribution of mean abundance of taxa and the distribution of fold change (as a function of mean abundance of taxa) by finite Mixture of Gaussian distributions.  Microbiome count data is then simulated from a negative binomial distribution. Detailed description of the `MixGassSim` method is presented in the paper ["Investigating statistical power of differential abundance studies"](https://doi.org/10.1371/journal.pone.0318820) [@agronahnbolker].  `RRSim`, on the other hand models the mean abundance of all taxa jointly with a mixed-effects model while accounting for correlations among taxa within subjects and zero inflation in microbiome data. Given the high dimensionality of microbiome data (usually having hundreds or thousands of taxa), modelling correlations between taxa requires estimating thousands or even millions of parameters for the correlation matrix. `RRSim` uses the reduced rank functionality implemented in the `glmmTMB` [@magnusson2017package] packages to reduce the number of parameter estimates required of the variance-correlation matrix. Details of this method is presented in the thesis ["A Novel Approach for Simulation-Based Power Estimation and Joint Modeling of Microbiome Counts"](https://macsphere.mcmaster.ca/handle/11375/31784) [@agronah2025novel]

#  Installation

Install the package from GitHub using `devtools`:

```{r, eval=FALSE}
install.packages("devtools")
devtools::install_github("magronah/power.nb")
```

# Estimating Statistical Power

Since the goal of differential abundance studies is to identify taxa that differ significantly between groups, statistical power must be estimated at the level of individual taxa. Because of the complexity of microbiome data, analytical approaches based on theoretical distributions of test statistics (e.g., non-central t or chi-squared distributions) are not feasible [@arnold2011simulation]. Therefore, power estimation typically relies on simulation-based methods that can mimic the characteristics of real microbiome data.

Statistical power for a given taxon depends on both its mean abundance and effect size (defined in this package as fold changes) [@agronahnbolker]. Thus, estimating the distributions of mean abundance and fold change of taxa explicitly will offer great benefit for estimation of statistical power for individual taxon. We use the `MixGaussSim` simulation approach to simulate microbiome data for power calculation due to its flexibly in modelling the distributions of taxa mean abundances and effect sizes explicitly as as well as their relationship. 


## Two ways to obtain parameters for data simulation using MixGaussSim
There are one of two ways to obtain the parameters of the `MixGaussSim` method for data simulation.  Users can:

**1. pre-specify a set of parameters:** To help users decide on plausible parameter values, we have run  `MixGaussSim` on some of the microbiome datasets used in the paper ["Microbiome differential abundance methods produce different results across 38 datasets"](10.1038/s41467-022-28034-z) [@Nearing2022] and presented the parameter estimates  obtained from each of these datasets ([see Appendix for the parameter estimates from these datasets](#appendix) ). 

**2. estimate parameters from an existing dataset:** Secondly, users can also obtain estimates directly from fitting the model implemented in  `MixGaussSim`  to exiting datasets. The following steps outlines the process for estimating parameters from an existing dataset. 

## Dataset

We use a subset of the Arctic Fire dataset, one of the datasets analyzed in [@Nearing2022]. The full dataset contains 148 samples and 31,100 taxa; however, for illustration and faster computation, only a subset is used to demonstrate how `MixGaussSim` works

```{r, eval=FALSE}
##Load libraries
library(tidyverse)
library(dplyr)
library(power.nb)
library(patchwork)

##Read count data and metadata
data <- read_qza(file.path(path, "ArcticFireSoils_table.qza"))$data

metadata <- read.table(
  file.path(path, "ArcticFireSoils_meta.tsv"),
  header = TRUE, sep = "\t",
  check.names = FALSE, comment.char = ""
)

keep_samples = colnames(data)
metadata <- metadata %>%
  setNames(c("SampleID", "Groups")) %>%
  filter(SampleID %in% keep_samples)

head(data); dim(data)
head(metadata);dim(metadata)
##############Select subset###############################

```

## Pre-filtering low abundant taxa

Low abundant tax exhibit high variability, posing challenges in detecting significant differences between groups [@love2014moderated]. Pre-filtering steps, as is routinely done in differential abundance analysis, is used to filter out these low abundant taxa. We filter out taxa with less that 10 count in less that 5 samples. 

```{r, eval=FALSE}
filter_data  = filter_low_count(
  countdata = data,
  metadata  = metadata,
  abund_thresh = 10,
  sample_thresh = 5,
  sample_colname = "SampleID",
  group_colname  = "Groups"
)

dim(filter_data)
```

## Foldchange and Dispersion Estimations

We estimate fold changes of each taxa and dispersions estimates from the negative binomial model implemented in the `DESeq2` package [@love2014moderated]. The model is .... 

*The negative binomial model, a standard approach for analyzing microbiome count data, is implemented in the \texttt{DEseq2}  {love2014moderated} and \texttt{edgeR} {robinson2010edger} R packages which are both widely used in microbiome analysis.  The model is described as follows: Let $K_{ij}$ denote the count data for the $i^{th}$ taxon in the $j^{th}$ sample. Then $K_{ij}$  follows a negative binomial distribution:* \begin{align} 
K_{ij} \sim \text{NB}(\text{mean} &= \mu_{ij}, \text{dispersion} = \alpha_{ij}), \nonumber \\
\mu_{ij} &= s_{j} q_{ij}   \\ 
\log q_{ij} &= \sum_r x_{jr}\beta_{ir} , \nonumber
\end{align} *where $\mu_{ij}$ and $s_{j}$ are the mean abundances and normalization constants respectively. $q_{ij}$ is the expected mean abundance of a given taxon in a sample prior to normalization. We assume  the dispersion parameter is constant for a given taxon. Thus, $\alpha_{ij}=\alpha_{i}$. The estimated coefficients $\hat \beta_{ir}$ are estimates of the effect sizes and $x_{jr}$ are the covariates. The relationship between the variance of counts and the dispersion is defined by $\text{var} (K_{ij}) = \mu_i + \alpha_i\mu_i^2$. In this study, the estimating procedure implemented in the \texttt{DESeq2} package ~\cite{love2014moderated,anders2010differential} in \texttt{R} is used for estimating $\hat \beta_{ir}$ and $\hat \alpha_i$.*






*We used the \texttt{DESeq2} package to estimate dispersion for the negative binomial model. Dispersion typically varies based on count abundance,*
from Deseq2 packge

```{r, eval = FALSE}
foldchange_est <- deseqfun(countdata = filter_data,
                           metadata  = metadata,
                          alpha_level = 0.1,
                          ref_name  = "Control",
                          group_colname = "Groups",
                          sample_colname = "SampleID")

logfoldchange =  foldchange_est$deseq_estimate$log2FoldChange
```


## Fit  log mean count 

```{r, eval = FALSE}
logmean    =  log(rowMeans(filter_data))
logmeanFit =  logmean_fit(logmean, sig = 0.05,
                         max.comp = 4, max.boot = 100)
logmeanFit
```



## Fit  Dispersions

*We used the \texttt{DESeq2} package to estimate dispersion for the negative binomial model. Dispersion typically varies based on count abundance, with rarer taxa exhibiting higher dispersion \citep{love2014moderated}. To accommodate this variability and to simulate dispersion for subsequent power analyses, we used a nonlinear function of mean abundance to model the dispersion estimates, as implemented in the \texttt{DESeq2} package:*

\begin{align} 
d = c_0 + \frac{c_1}{m},
\end{align}
where $d$ and $m$ denote the scaled dispersion and mean abundance respectively. The term $c_0$ represents the asymptotic dispersion level for high abundance taxa, and $c_1$ captures additional dispersion variability. 


```{r, eval = FALSE}

dispersion    =  foldchange_est$dispersion
dispersionFit =  dispersion_fit(dispersion, logmean)
```

## Fit log fold change

```{r, eval = FALSE}
## Fit foldchange from Deseq
logfoldchangeFit <- logfoldchange_fit(logmean,
                                       logfoldchange,
                                       ncore = 3,
                                       max_sd_ord = 2,
                                       max_np = 5,
                                       minval = -5,
                                       maxval = 5,
                                       itermax = 100,
                                       NP = 800,
                                       seed = 100)
```


## Simulate count data

```{r, eval = FALSE}

### Simulated log mean count and log foldchange using the fitted parameters

logmean_param       =  logmeanFit$logmean_param
logfoldchange_param =  logfoldchangeFit

notu  = dim(filter_data)[1]
logmean_sim  =  logmean_sim_fun(logmean_param, notu)

logfoldchange_sim  =  logfoldchange_sim_fun(logmean_sim = logmean_sim,
                                            logfoldchange_param = 
                                            logfoldchange_param,
                                            max_lfc  = 15,
                                            max_iter = 30000)
```


```{r, eval = FALSE}

ntreat = sum(metadata$Groups == "Fire")
ncont  = sum(metadata$Groups == "Control")
dispersion_param  =  dispersionFit$param

nsim = 100
countdata_sims = countdata_sim_fun(logmean_param,
                                   logfoldchange_param,
                                   dispersion_param,
                                   nsamp_per_group = NULL,
                                   ncont = ncont,
                                   ntreat = ntreat,
                                   notu,
                                   nsim = nsim,
                                   disp_scale = 0.3,
                                   max_lfc = 15,
                                   maxlfc_iter = 1000,
                                   seed = 121)


dim(countdata_sims$treat_countdata_list$sim_1)
dim(countdata_sims$control_countdata_list$sim_1)
dim(countdata_sims$countdata_list$sim_1)
dim(countdata_sims$metadata_list$sim_1)


length(countdata_sims$logfoldchange_list$sim_1)
length(countdata_sims$logmean_list$sim_1)
###############################################################
```

### Compare Simulation with the data

log mean count and log fold change from simulation with data
```{r, eval = FALSE}
dd  = data.frame(logmean  = c(logmean,
                              countdata_sims$logmean_list$sim_1),
                 logfoldchange  = c(foldchange_est$logfoldchange,
                                  countdata_sims$logfoldchange_list$sim_1),
                 type  = rep(c("observation","simulation"), each = notu) )

p1 = ggplot(dd, aes(x = logmean, group = type, colour = type)) +
  geom_density()  +
  theme_bw()

p2 = ggplot(dd, aes(x = logfoldchange, group = type, colour = type)) +
  geom_density()  +
  theme_bw()

(p1|p2) + plot_layout(guides = "collect")
```


## Estimate p-values associated to fold changes for each taxa

We now run each simulated count adata to the to calculate pvalues associated to each  foldchanes for each taxa. ]


```{r, eval = FALSE}

###############################################################
countdata_list  =   countdata_sims$countdata_list
metadata_list   =   countdata_sims$metadata_list
desq_est   =   deseq_fun_est(metadata_list =  metadata_list,
                            countdata_list =  countdata_list,
                            alpha_level    =  0.1,
                            group_colname  = "Groups",
                            sample_colname = "Samples",
                            num_cores      =  4,
                            ref_name       = "control")
###############################################################
true_lmean_list    =    countdata_sims$logmean_list
deseq_est_list     =    lapply(desq_est, function(x){x$deseq_estimate})
true_lfoldchange_list = countdata_sims$logfoldchange_list
###############################################################
```

## Fit Generalized Additive Model (GAM) for power estimation 

```{r, eval = FALSE}
gamFit <- gam_fit(deseq_est_list,
                  true_lfoldchange_list,
                  true_lmean_list,
                  grid_len = 50,
                  alpha_level=0.1)
  

cont_breaks     =  seq(0,1,0.1)
combined_data   =  gamFit$combined_data
power_estimate  =  gamFit$power_estimate
#plot(gamFit$fit_2d)

contour_plot <- contour_plot_fun(combined_data,
                                 power_estimate,
                                 cont_breaks)
contour_plot
```


## Estimate statistical power given fold change and mean abundance for taxa



# Sample size calculation

## Simulate count data for various ranges of sample sizes

```{r, eval = FALSE}
nsim = 50
nsamp_vec = c(20, 50, 70)
countdata_sims_list  =  list()
for(j in 1:length(nsamp_vec)){
  countdata_sims_list[[j]]  =  countdata_sim_fun(logmean_param,
                                                 logfoldchange_param,
                                                 dispersion_param,
                                                 nsamp_per_group = nsamp_vec[j],
                                                 ncont  = NULL,
                                                 ntreat = NULL,
                                                 notu,
                                                 nsim = nsim,
                                                 disp_scale = 0.3,
                                                 max_lfc = 15,
                                                 maxlfc_iter = 1000,
                                                 seed = 121)
}

names(countdata_sims_list) = paste0("sample_",nsamp_vec)
###############################################################
```

## Estimate p-values associated to fold changes for each taxa for simulated data per sample size

```{r, eval = FALSE}
desq_est_list  =  list()
for(i in 1:length(countdata_sims_list)){
  
  countdata_list       =   countdata_sims_list[[i]]$countdata_list
  metadata_list        =   countdata_sims_list[[i]]$metadata_list
  desq_est_list[[i]]   =   deseq_fun_est(metadata_list =  metadata_list,
                               countdata_list =  countdata_list,
                               alpha_level    =  0.1,
                               group_colname  = "Groups",
                               sample_colname = "Samples",
                               num_cores      =  4,
                               ref_name       = "control")
  
}
```


## Fit Generalized Additive Model (GAM) for power estimation 



## Estimate sample size for a given statistical power, fold change and mean abundance




##### Data preprocessing 
Low abundant tax exhibit high variability, posing challenges in detecting significant differences between groups cite{m}. Pre-filtering steps, as is routinely done in differential abundance analysis, is used to filter out these low abundant taxa. In this vignette, we filter out taxa with less that 10 count in less that 5 samples. 

```{r, eval=FALSE}
# load library
library(power.nb) 

#filter out low abundant taxa
filter_data  = filter_low_count(countdata = data,
                                metadata  = metadata,
                                abund_thresh = 10,
                                sample_thresh = 5,
                                sample_colname = "SampleID",
                                group_colname  = "Groups")

head(filter_data)
```

##### Model Fitting

```{r, eval=FALSE}
#Fit log mean count
logmean    =  log(rowMeans(filter_data))
logmeanFit =  logmean_fit(logmean, sig = 0.05, 
                         max.comp = 4, max.boot = 100)
names(logmeanFit)

#Estimate foldchange from Deseq
foldchange_est <- deseqfun(countdata = data,
                           metadata  = metadata,
                          alpha_level = 0.1,
                          ref_name  = "Control",
                          group_colname = "Groups",
                          sample_colname = "SampleID")

logfoldchange =  foldchange_est$log2FoldChange

## Fit foldchange from Deseq
logfoldchangeFit <- logfoldchange_fit(logmean,
                                       logfoldchange,
                                       ncore = 2,
                                       max_sd_ord = 2,
                                       max_np = 5,
                                       minval = -5,
                                       maxval = 5,
                                       itermax = 100,
                                       NP = 800,
                                       seed = 100)

logfoldchangeFit
```


## Simulating Data

- Simulate log mean count from the fitted Mixture of Gaussian (using existing dataset) or from the pre-specified parameters for the Gaussian Mixture 

- Simulate log fold change using the estimated parameters or the prespecified parameters and the simulated as the input for the variance and mean of the log fold change 

- Simulate dispersion parameters from the estimated nonlinear function of the dispersion function 

- Simulate count data from a negative binomial model and then 

- Use the simulated procedure outline above to simulate n number of count data 


```{r, eval=FALSE}
sim <- simulate_data(fit,
                     n_taxa = 1000,
                     n_per_group = c(30, 30),
                     fold_changes = c(1.5, 2, 4),
                     nsim = 100)
```


## Power estimation procedure

- Fit the count data with the negative binomial model in the desert package to estimate pvalues for each fold change estimated fold change

- Construct a vector of binaries with 1 for a taxa where value is less than a specified threshold and 0 otherwise. 

- We fit a Generalised additive model to predict the probability of obtaining 1  (also the statistical power) for any combination of mean count and log fold change 

- Figure shows a contour plot for 3  of the datasets. From the plots, there is low statistical power. 
  a Concatenation all the 







# Appendix 

```{r, echo=FALSE}
library(knitr)
library(kableExtra)

# Example data (two rows like in your LaTeX version)
df <- data.frame(
  `Data description` = c("Example row 1", "Example row 2"),
  n1 = c(5, 5),
  mu1 = c("(2,3,4,5,7)", "(2,3,4,5,7)"),
  sigma1 = c("(2,3,4,5,7)", "(2,3,4,5,7)"),
  p1 = c("(2,3,4,5,7)", "(2,3,4,5,7)"),
  n2 = c(5, 5),
  mu2 = c("(2,3,4,5,7)", "(2,3,4,5,7)"),
  sigma2 = c("(2,3,4,5,7)", "(2,3,4,5,7)"),
  p2 = c("(2,3,4,5,7)", "(2,3,4,5,7)"),
  fx = c("(2,3,4,5,7)", "(2,3,4,5,7)")
)

kbl(df, booktabs = TRUE, longtable = TRUE,
    caption = "Data description and parameter estimates from actual microbiome datasets") %>%
  kable_styling(latex_options = c("hold_position", "repeat_header")) %>%
  add_header_above(c(" " = 1, "Log mean count" = 4, "Log foldchange" = 5)) %>%
  add_header_above(c(" " = 1, "Parameters" = 9)) # optional extra grouping

```


